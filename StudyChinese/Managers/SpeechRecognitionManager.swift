//
//  SpeechRecognitionManager.swift
//  StudyChinese
//
//  Created by AI Assistant on 1/20/25.
//

import Foundation
import Speech
import AVFoundation
import Combine

class SpeechRecognitionManager: ObservableObject {
    @Published var recognizedText = ""
    @Published var isRecording = false
    @Published var isAuthorized = false
    @Published var authorizationError: String?
    @Published var confidence: Float = 0.0
    
    private let audioEngine = AVAudioEngine()
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private var isProcessing = false
    private var recordingTimer: Timer?
    
    init() {
        requestAuthorization()
    }
    
    private func requestAuthorization() {
        SFSpeechRecognizer.requestAuthorization { [weak self] authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    self?.isAuthorized = true
                case .denied:
                    self?.authorizationError = "éŸ³å£°èªè­˜ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ"
                case .restricted:
                    self?.authorizationError = "éŸ³å£°èªè­˜ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™"
                case .notDetermined:
                    self?.authorizationError = "éŸ³å£°èªè­˜ã®èªè¨¼ãŒæœªç¢ºå®šã§ã™"
                @unknown default:
                    self?.authorizationError = "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
                }
            }
        }
        
        AVAudioSession.sharedInstance().requestRecordPermission { [weak self] allowed in
            DispatchQueue.main.async {
                if !allowed {
                    self?.authorizationError = "ãƒã‚¤ã‚¯ã®ä½¿ç”¨è¨±å¯ãŒå¿…è¦ã§ã™"
                }
            }
        }
    }
    
    func startRecording() {
        guard isAuthorized && !isProcessing else { return }
        
        isProcessing = true
        
        // æ—¢å­˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å®‰å…¨ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanupResources()
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®š
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.record, mode: .measurement, options: [.duckOthers, .allowBluetooth])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            print("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: \(error)")
            isProcessing = false
            return
        }
        
        // éŸ³å£°èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            print("èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            isProcessing = false
            return
        }
        
        // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºãƒ»é«˜ç²¾åº¦è¨­å®š
        recognitionRequest.shouldReportPartialResults = true // éƒ¨åˆ†çµæœã‚’æœ‰åŠ¹ã«ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        recognitionRequest.requiresOnDeviceRecognition = false // ã‚ªãƒ³ãƒ©ã‚¤ãƒ³èªè­˜ã§ç²¾åº¦å‘ä¸Š
        
        let inputNode = audioEngine.inputNode
        
        // ä¸­å›½èªã®éŸ³å£°èªè­˜ã‚’è¨­å®š
        guard let chineseRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN")) else {
            print("ä¸­å›½èªéŸ³å£°èªè­˜ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            isProcessing = false
            return
        }
        
        recognitionTask = chineseRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            DispatchQueue.main.async {
                guard let self = self else { return }
                
                if let result = result {
                    self.recognizedText = result.bestTranscription.formattedString
                    
                    // ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆã‚ˆã‚Šæ­£ç¢ºãªæ–¹æ³•ï¼‰
                    if !result.bestTranscription.segments.isEmpty {
                        let totalConfidence = result.bestTranscription.segments.reduce(0.0) { sum, segment in
                            return sum + segment.confidence
                        }
                        self.confidence = totalConfidence / Float(result.bestTranscription.segments.count)
                    }
                    
                    // æœ€çµ‚çµæœã®å ´åˆã¯è‡ªå‹•åœæ­¢
                    if result.isFinal {
                        self.stopRecording()
                    }
                }
                
                if let error = error {
                    print("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: \(error)")
                    self.stopRecording()
                }
            }
        }
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æœ€é©åŒ–
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { [weak self] buffer, _ in
            self?.recognitionRequest?.append(buffer)
        }
        
        audioEngine.prepare()
        
        do {
            try audioEngine.start()
            
            // UIæ›´æ–°ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚
            DispatchQueue.main.async {
                self.isRecording = true
                self.recognizedText = ""
                self.confidence = 0.0
                self.isProcessing = false
            }
            
            // å®‰å…¨ã®ãŸã‚è‡ªå‹•åœæ­¢ã‚¿ã‚¤ãƒãƒ¼ï¼ˆ30ç§’ï¼‰
            recordingTimer = Timer.scheduledTimer(withTimeInterval: 30.0, repeats: false) { [weak self] _ in
                self?.stopRecording()
            }
            
        } catch {
            print("éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: \(error)")
            isProcessing = false
        }
    }
    
    func stopRecording() {
        guard isRecording else { return }
        
        cleanupResources()
        
        DispatchQueue.main.async {
            self.isRecording = false
            self.isProcessing = false
        }
    }
    
    // æ–°ã—ã„ç·´ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    func resetSession() {
        cleanupResources()
        
        DispatchQueue.main.async {
            self.recognizedText = ""
            self.confidence = 0.0
            self.isRecording = false
            self.isProcessing = false
        }
    }
    
    private func cleanupResources() {
        // ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
        recordingTimer?.invalidate()
        recordingTimer = nil
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        
        // èªè­˜ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        recognitionTask?.cancel()
        recognitionTask = nil
        
        // èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’çµ‚äº†
        recognitionRequest?.endAudio()
        recognitionRequest = nil
    }
    
    // ã‚ˆã‚Šé«˜ç²¾åº¦ãªãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦è¨ˆç®—ï¼ˆLevenshteinè·é›¢ï¼‰
    func calculateSimilarity(original: String, recognized: String) -> Double {
        let originalCleaned = original.trimmingCharacters(in: .whitespacesAndNewlines)
        let recognizedCleaned = recognized.trimmingCharacters(in: .whitespacesAndNewlines)
        
        if originalCleaned.isEmpty && recognizedCleaned.isEmpty { return 1.0 }
        if originalCleaned.isEmpty || recognizedCleaned.isEmpty { return 0.0 }
        
        // å®Œå…¨ä¸€è‡´ã®å ´åˆ
        if originalCleaned == recognizedCleaned {
            return 1.0
        }
        
        // Levenshteinè·é›¢ã‚’ä½¿ç”¨ã—ãŸé¡ä¼¼åº¦è¨ˆç®—
        let distance = levenshteinDistance(originalCleaned, recognizedCleaned)
        let maxLength = max(originalCleaned.count, recognizedCleaned.count)
        
        return 1.0 - (Double(distance) / Double(maxLength))
    }
    
    private func levenshteinDistance(_ s1: String, _ s2: String) -> Int {
        let s1Array = Array(s1)
        let s2Array = Array(s2)
        let s1Count = s1Array.count
        let s2Count = s2Array.count
        
        var matrix = Array(repeating: Array(repeating: 0, count: s2Count + 1), count: s1Count + 1)
        
        for i in 0...s1Count {
            matrix[i][0] = i
        }
        
        for j in 0...s2Count {
            matrix[0][j] = j
        }
        
        for i in 1...s1Count {
            for j in 1...s2Count {
                let cost = s1Array[i-1] == s2Array[j-1] ? 0 : 1
                matrix[i][j] = min(
                    matrix[i-1][j] + 1,      // deletion
                    matrix[i][j-1] + 1,      // insertion
                    matrix[i-1][j-1] + cost  // substitution
                )
            }
        }
        
        return matrix[s1Count][s2Count]
    }
    
    // å˜èªãƒ¬ãƒ™ãƒ«ã§ã®ç™ºéŸ³åˆ†æ
    private func analyzeWordLevel(original: String, recognized: String) -> [WordLevelResult] {
        let originalWords = segmentChineseText(original)
        let recognizedWords = segmentChineseText(recognized)
        
        var results: [WordLevelResult] = []
        let maxCount = max(originalWords.count, recognizedWords.count)
        
        for i in 0..<maxCount {
            let targetWord = i < originalWords.count ? originalWords[i] : ""
            let spokenWord = i < recognizedWords.count ? recognizedWords[i] : ""
            
            if !targetWord.isEmpty {
                let wordSimilarity = calculateSimilarity(original: targetWord, recognized: spokenWord)
                let isCorrect = wordSimilarity >= 0.8 // 80%ä»¥ä¸Šã§æ­£è§£ã¨ã™ã‚‹
                
                let feedback: String
                if isCorrect {
                    feedback = "æ­£ç¢º"
                } else if wordSimilarity >= 0.6 {
                    feedback = "ã‚‚ã†å°‘ã—"
                } else if spokenWord.isEmpty {
                    feedback = "æœªèªè­˜"
                } else {
                    feedback = "è¦ç·´ç¿’"
                }
                
                results.append(WordLevelResult(
                    word: spokenWord,
                    targetWord: targetWord,
                    similarity: wordSimilarity,
                    confidence: confidence,
                    isCorrect: isCorrect,
                    feedback: feedback
                ))
            }
        }
        
        return results
    }
    
    // ä¸­å›½èªãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    private func segmentChineseText(_ text: String) -> [String] {
        // ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚ŠãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if text.contains(" ") {
            return text.components(separatedBy: " ").filter { !$0.isEmpty }
        }
        
        // å¥èª­ç‚¹ã‚’é™¤å»
        let cleanedText = text.replacingOccurrences(of: "[ã€‚ï¼Œã€ï¼Ÿï¼ï¼šï¼›]", with: "", options: .regularExpression)
        
        // ã‚ˆã‚Šæ™ºèƒ½ãªä¸­å›½èªåˆ†è©ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        return segmentChineseTextIntelligently(cleanedText)
    }
    
    // æ™ºèƒ½åˆ†è©ï¼ˆåŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
    private func segmentChineseTextIntelligently(_ text: String) -> [String] {
        var segments: [String] = []
        var currentSegment = ""
        var i = text.startIndex
        
        while i < text.endIndex {
            let char = String(text[i])
            
            // 2æ–‡å­—ã®ä¸€èˆ¬çš„ãªçµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯
            if i < text.index(before: text.endIndex) {
                let nextChar = String(text[text.index(after: i)])
                let twoCharWord = char + nextChar
                
                if isCommonTwoCharWord(twoCharWord) {
                    if !currentSegment.isEmpty {
                        segments.append(currentSegment)
                        currentSegment = ""
                    }
                    segments.append(twoCharWord)
                    i = text.index(i, offsetBy: 2)
                    continue
                }
            }
            
            // å˜ä¸€æ–‡å­—ã®å‡¦ç†
            if isStandaloneChar(char) {
                if !currentSegment.isEmpty {
                    segments.append(currentSegment)
                    currentSegment = ""
                }
                segments.append(char)
            } else {
                currentSegment += char
            }
            
            i = text.index(after: i)
        }
        
        if !currentSegment.isEmpty {
            segments.append(currentSegment)
        }
        
        return segments.filter { !$0.isEmpty }
    }
    
    // ä¸€èˆ¬çš„ãª2æ–‡å­—å˜èªã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    private func isCommonTwoCharWord(_ word: String) -> Bool {
        let commonTwoCharWords = [
            "ä¸­å›½", "å­¦ä¹ ", "å­¦ç¿’", "ç»ƒä¹ ", "ç·´ç¿’", "æœ‹å‹", "è€å¸ˆ", "è€å¸«", "å­¦ç”Ÿ", "å­¦ç”Ÿ",
            "ä»Šå¤©", "æ˜å¤©", "æ˜¨å¤©", "ç°åœ¨", "ç¾åœ¨", "æ—¶é—´", "æ™‚é–“", "å·¥ä½œ", "å…¬å¸",
            "å®¶é‡Œ", "å­¦æ ¡", "å­¦æ ¡", "åŒ»é™¢", "é†«é™¢", "é“¶è¡Œ", "éŠ€è¡Œ", "å•†åº—", "é¥­åº—",
            "å–œæ¬¢", "å–œæ­¡", "çŸ¥é“", "è®¤ä¸º", "èªç‚º", "è§‰å¾—", "è¦ºå¾—", "å¸Œæœ›", "æƒ³è¦",
            "ä»€ä¹ˆ", "ä»€éº¼", "æ€ä¹ˆ", "æ€éº¼", "ä¸ºä»€ä¹ˆ", "ç‚ºä»€éº¼", "å“ªé‡Œ", "å“ªè£¡"
        ]
        return commonTwoCharWords.contains(word)
    }
    
    // ç‹¬ç«‹ã—ãŸæ–‡å­—ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    private func isStandaloneChar(_ char: String) -> Bool {
        let standaloneChars = [
            "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "å€‘", "çš„", "äº†", "åœ¨", "æ˜¯", "æœ‰", "ä¸", "å¾ˆ", "ä¹Ÿ", "éƒ½",
            "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å", "ç™¾", "åƒ", "ä¸‡", "è¬"
        ]
        return standaloneChars.contains(char)
    }
    
    // æ”¹å–„ã•ã‚ŒãŸç™ºéŸ³è©•ä¾¡
    func evaluatePronunciation(original: String, recognized: String) -> PronunciationResult {
        let similarity = calculateSimilarity(original: original, recognized: recognized)
        let confidenceScore = Double(confidence)
        
        // å˜èªãƒ¬ãƒ™ãƒ«ã®åˆ†æã‚’å®Ÿè¡Œ
        let wordLevelResults = analyzeWordLevel(original: original, recognized: recognized)
        
        // ã‚ˆã‚Šè©³ç´°ãªè©•ä¾¡åŸºæº–
        // 1. éŸ³å£°èªè­˜ã®ä¿¡é ¼åº¦ (40%)
        // 2. ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦ (60%)
        let combinedScore = (similarity * 0.6) + (confidenceScore * 0.4)
        
        // ã‚ˆã‚Šè©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        let similarityPercent = Int(similarity * 100)
        let confidencePercent = Int(confidenceScore * 100)
        
        if combinedScore >= 0.9 {
            return PronunciationResult(
                score: combinedScore,
                grade: .excellent,
                feedback: "ç´ æ™´ã‚‰ã—ã„ç™ºéŸ³ã§ã™ï¼\nğŸ“Š é¡ä¼¼åº¦: \(similarityPercent)% | ä¿¡é ¼åº¦: \(confidencePercent)%",
                wordLevelResults: wordLevelResults
            )
        } else if combinedScore >= 0.75 {
            return PronunciationResult(
                score: combinedScore,
                grade: .good,
                feedback: "ã¨ã¦ã‚‚è‰¯ã„ç™ºéŸ³ã§ã™ï¼\nğŸ“Š é¡ä¼¼åº¦: \(similarityPercent)% | ä¿¡é ¼åº¦: \(confidencePercent)%",
                wordLevelResults: wordLevelResults
            )
        } else if combinedScore >= 0.5 {
            return PronunciationResult(
                score: combinedScore,
                grade: .fair,
                feedback: "ã‚‚ã†å°‘ã—ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚\nğŸ“Š é¡ä¼¼åº¦: \(similarityPercent)% | ä¿¡é ¼åº¦: \(confidencePercent)%\nğŸ’¡ ç›®æ¨™: é¡ä¼¼åº¦80%ä»¥ä¸Šã€ä¿¡é ¼åº¦70%ä»¥ä¸Š",
                wordLevelResults: wordLevelResults
            )
        } else {
            return PronunciationResult(
                score: combinedScore,
                grade: .needsImprovement,
                feedback: "ç™ºéŸ³ã®ç·´ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚\nğŸ“Š é¡ä¼¼åº¦: \(similarityPercent)% | ä¿¡é ¼åº¦: \(confidencePercent)%\nğŸ’¡ ã‚†ã£ãã‚Šã¯ã£ãã‚Šã¨è©±ã—ã¦ã¿ã¦ãã ã•ã„",
                wordLevelResults: wordLevelResults
            )
        }
    }
}

struct WordLevelResult {
    let word: String
    let targetWord: String
    let similarity: Double
    let confidence: Float
    let isCorrect: Bool
    let feedback: String
}

struct PronunciationResult {
    let score: Double
    let grade: PronunciationGrade
    let feedback: String
    let wordLevelResults: [WordLevelResult]
}

enum PronunciationGrade {
    case excellent
    case good
    case fair
    case needsImprovement
    
    var emoji: String {
        switch self {
        case .excellent: return "ğŸŒŸ"
        case .good: return "ğŸ‘"
        case .fair: return "ğŸ˜Š"
        case .needsImprovement: return "ğŸ”„"
        }
    }
    
    var color: String {
        switch self {
        case .excellent: return "green"
        case .good: return "blue"
        case .fair: return "orange"
        case .needsImprovement: return "red"
        }
    }
    
    var description: String {
        switch self {
        case .excellent:
            return "å®Œç’§ãªç™ºéŸ³"
        case .good:
            return "è‰¯ã„ç™ºéŸ³"
        case .fair:
            return "ç·´ç¿’ãŒå¿…è¦"
        case .needsImprovement:
            return "æ”¹å–„ãŒå¿…è¦"
        }
    }
}